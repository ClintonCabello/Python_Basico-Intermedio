{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesión 9: Librería Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La librería Pandas desarrollada para el análisis. Fue desarrollada en NumPy. La librería Pandas trae la riqueza de R al mundo de Python. Tiene eficiente estructuras de datos para procesar los datos, unir datos y leerlos de varias fuentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **serie** en Pandas es un vector unidimensional con un índice que puede especificarse o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería Pandas desde Python.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de una serie a partir de 5 números aleatorios.\n",
    "pd.Series(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_1 = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_1['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_1[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **DataFrame** son estructuras bidimensionales donde las columnas está etiquetadas con su valor y pueden ser de tipos distintos. Una analogía a un Dataframe podria ser una hoja de cálculo Excel o una tabla de una base de datos.\n",
    "\n",
    "De forma opcional un Dataframe puede tener un ínidce. Ese ínidce será el nombre de las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frames que provienen de diccionarios de series.\n",
    "d = {'c1': pd.Series(['A', 'B', 'C']),'c2': pd.Series([1., 2., 3., 4.])}\n",
    "data1 = pd.DataFrame(d)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frames que provienen de diccionarios de listas.\n",
    "d = {'c1': ['A', 'B', 'C', 'D'],'c2': [1.0, 2.0, 3.0, 4.0]}\n",
    "data2 = pd.DataFrame(d)\n",
    "display(data2)\n",
    "print(type(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_range genera una lista de fechas.\n",
    "dates = pd.date_range('20130101',periods=6)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index=> es el índice y indica el nombre de cada fila. en este caso metemos\n",
    "#el array de dates del paso anterior. Columns identifica la etiqueta de las\n",
    "#columnas.\n",
    "df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#También lo podemos imprimir más bonito (solamente en Jupyter)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipos de datos de un dataframe pueden ser diferentes. Es la misma idea que una tabla de la base de datos. Cada columna puede ser de un tipo diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series(42,index=list(range(4)))\n",
    "display(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.DataFrame({'A':1.0,\n",
    "                    'B':pd.Timestamp('20130102'),\n",
    "                    'C':pd.Series(42,index=list(range(4)),dtype='float32'),\n",
    "                    'D':2,\n",
    "                    'E':pd.Categorical(['test','train','test','train']),\n",
    "                    'F': \"foo\" \n",
    "                   })\n",
    "display(df2)\n",
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas funciones útiles:\n",
    "* pd.Timestamp(): genera una campo de tipo timestamp.\n",
    "* pd.Series() Genera una serie de números. El index es el índice de la serie que es de tipo entero. Range genera los 4 primeros números.\n",
    "* pd.Categorical() genera una lista de categorías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestran diversas funciones útiles para acceder a las \n",
    "características de un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "print('----------------------------------------')\n",
    "print(df.columns)\n",
    "print('----------------------------------------')\n",
    "print(df.values)\n",
    "print('----------------------------------------')\n",
    "display(df)\n",
    "print(\"=========================================\")\n",
    "print(df.describe())    #principales estadisticos de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe transpuesto\n",
    "display(df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordenación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar por índices\n",
    "display(df)\n",
    "display(df.sort_index(axis=0,ascending=False)) # ordena las filas (axis 0)\n",
    "display(df.sort_index(axis=1,ascending=False)) # ordena las columnas (axis 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar por columnas\n",
    "display(df)\n",
    "display(df.sort_values(by=['C'],ascending=False)) \n",
    "# selecciona la columna que utilizaremos como criterio de ordenación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones head y tail nos muestran los primeros y últimos elementos respectivamente. Útiles para resumir el dataframe cuanod estos son muy grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(3))\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceder a una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[['B']])\n",
    "display(df.B) # Ojo con los nombres de las columnas que sea palabras con espacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acceder a una fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[1:4])\n",
    "display(df['2013-01-02':'2013-01-04']) # selección por filas con un rango de numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **loc()** define una selección a traves de un indice. Selecciona por filas en función del indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(df.loc[[dates[1]]])   #el doble corchete convierte la salida en un dataframe\n",
    "display(df.loc[['2013-01-02']])\n",
    "display(df.loc[:,['A','B']]) #selecciona todas las filas y las columnas A y B\n",
    "display(df.loc['2013-01-01':'2013-01-02',['A','B']]) #selecciona las filas '2013-01-01' a '2013-01-02' y las columnas A y B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iloc()** es similar, pero utiliza enteros en vez de los nombres de los campos (podemos aplicar indexing y slicing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.iloc[3])    # devuelve como resultado una serie\n",
    "display(df.iloc[[3]])    # devuelve como resultado un dataframe\n",
    "display(df.iloc[0:2,0:2])\n",
    "display(df.iloc[[1,2,4],[0,2,3]])\n",
    "display(df.iloc[:,[0,2,3]])\n",
    "display(df.iloc[[0,2,4],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtrado condicional:** Similar a select where condition de sql. Permite consular solo los valores que cumplan con la condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(df[df.B > 0]) # muestra los valores de la tabla en cuya columna B su valor sea mayor que 0\n",
    "display(df[df > 0]) # muestra los elementos de la tabla que sean mayores que cero. El resto serán NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cruzado de datos (merge)** similar a la que se puede hacer en BBDD con join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla1 = pd.DataFrame({'key1' : ['A','B','C','D'], 'lval':[1,2,3,4]})\n",
    "tabla2 = pd.DataFrame({'key2' : ['C','D','E','F'], 'rval':[5,6,7,8]})\n",
    "display(tabla1)\n",
    "display(tabla2)\n",
    "new1 = pd.merge(tabla1,tabla2,left_on='key1',right_on='key2', how=\"left\")  \n",
    "# si el campo para fusionar se llam igual en ambas tablas, basta con poner on=\" \"\n",
    "#how : forma en la que combinamos con una intersección o con una unión, \n",
    "#sólo con la izquierda o sólo con la tabla de la derecha\n",
    "#left, right, inner o outher.\n",
    "display(new1)\n",
    "new2 = pd.merge(tabla1,tabla2,left_on='key1',right_on='key2', how=\"inner\") \n",
    "display(new2)\n",
    "new3 = pd.merge(tabla1,tabla2,left_on='key1',right_on='key2', how=\"right\") \n",
    "display(new3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer agrupaciones, podemos usar **groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.DataFrame({'A' : ['foo', 'bar'] * 12,\n",
    "                   'B' : ['one', 'two', 'three']*8,\n",
    "                   'val1' : np.random.rand(24),\n",
    "                   'val2' : np.random.rand(24)})\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = f.groupby(['A','B'])\n",
    "print(\"-------------\")\n",
    "display(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los grupos no se pueden mostrar, \n",
    "# group está pensado para ejecutar posteriormente una acción\n",
    "# por ejemplo sumar\n",
    "print(\"-----suma agrupada------\")\n",
    "display(group.sum())\n",
    "print(\"-----estadisticos agrupados------\")\n",
    "display(group.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una agrupación directa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.groupby(['A','B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora aplicamos un filtro sobre una agrupación (similar al having de SQL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrup = f.groupby(['A','B']).sum()\n",
    "agrup[agrup.val1 > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero veo que existe un método llamado **join()**. ¿Tienen la misma funcionalidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla1.set_index('key1').join(tabla2.set_index('key2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla1.set_index('key1').join(tabla2.set_index('key2'),how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues la respuesta es que **`No`**. El método `join()` se usa cuando se quiere cruzar dos DataFrames en base a sus índices o en base al(a los) índice(s) de un DataFrame con la(s) columna(s) de la otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Te acuerdas de las tablas dinámicas de Excel? Pues, DataFrame tiene una funcionalidad parecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.pivot_table(index=\"A\", columns=\"B\", values=\"val1\", aggfunc=\"mean\", margins=True, margins_name='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programación Funcional con Pandas\n",
    "Las funciones `lambda`, `map` y `filter` vistas en los notebooks anteriores, son utilizadas por los DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino una función lambda para poder sumar una unidad a un valor\n",
    "potencia = lambda x: x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar una unidad a una columna\n",
    "f[\"val1\"].apply(potencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puedo hacer operaciones con más de una columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraccion = lambda row: round(row[\"val1\"] / row[\"val2\"], 2) if row[\"val2\"] > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"fraccion\"] = f.apply(fraccion, axis=1)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Map\n",
    "Nos permite asociar un valor con otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"B\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingreso_rng_dict = {v: k for k, v in enumerate(f[\"B\"].unique().tolist())}\n",
    "ingreso_rng_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[\"B_COD\"] = f[\"B\"].map(ingreso_rng_dict)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter\n",
    "Nos permite filtrar en base a los índices en cualquiera de los axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.filter(items=[\"A\", \"B\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo las columnas que empiecen con B\n",
    "f.filter(like=\"B\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL - WHERE column_name LIKE '%o%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[f['B'].str.contains('o')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL - WHERE column_name LIKE 'o%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[f['B'].str.startswith('o')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL - WHERE column_name LIKE '%e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[f['B'].str.endswith('e')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar y exportar datos en formato csv y txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos en formato csv.\n",
    "d_students = pd.read_csv('data/students.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los primeros registros\n",
    "d_students.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos en formato txt.\n",
    "d_txt = pd.read_csv('data/students.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_txt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar datos de un data frame a un csv y txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('prueba.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('prueba.txt', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso de **read_csv** con *parse_dates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y %m') # depende del formato que tenga la fecha en tu archivo\n",
    "data = pd.read_csv(\"data/AirPassengers_2012_2016_2.csv\", parse_dates= {'yearmonth':['Year', 'Month']}, date_parser=dateparse,index_col='yearmonth')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores como cabeceras de las columnas en lugar de nombres de variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "incomes_per_religion = pd.read_csv(\"data/religion_income.csv\")\n",
    "incomes_per_religion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomes_per_religion_tidy = pd.melt(incomes_per_religion, \n",
    "    id_vars=['religion'], var_name='income', value_name='frequency')\n",
    "incomes_per_religion_tidy.set_index('religion',inplace=True)\n",
    "incomes_per_religion_tidy.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar y exportar datos en formato xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos en formato xls.\n",
    "d = pd.read_excel('data/students.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenando por algún campo específico\n",
    "d.sort_values('AREA NAME', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_excel(\"data/billboard.xlsx\")\n",
    "billboard.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_cols = [\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\"]\n",
    "songs = billboard[songs_cols].drop_duplicates() # Eliminamos posibles duplicados\n",
    "songs = songs.reset_index(drop=True) # Se reinicia el índice eliminando el antiguo\n",
    "songs[\"song_id\"] = songs.index\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar datos de un data frame a formato Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_excel(\"data/canciones.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos en formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el paquete JSON.\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = open('data/students.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntar varias tablas con nombres consecutivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/religion_income_1.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/religion_income_2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "#permite juntar varias tablas con nombres consecutivos\n",
    "filenames = glob('data/religion_income_*.csv')\n",
    "dataframes = []\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n",
    "df3 = pd.concat(dataframes)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar a los valores perdidos.\n",
    "d_students['REGION'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar a los valores no perdidos.\n",
    "d_students['PCT OVERWEIGHT'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantificar a los valores perdidos.\n",
    "d_students['PCT OVERWEIGHT'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantificar a los valores no perdidos.\n",
    "d_students['PCT OVERWEIGHT'].notnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar a los valores perdidos.\n",
    "d_students['PCT OVERWEIGHT'].dropna().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_students.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar a cualquier registro que tenga por lo menos un campo con valor perdido: how='any'\n",
    "# Para eliminar filas completas con valores todos los valores vacíos: how='all'\n",
    "d = d_students.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantificar a los valores perdidos.\n",
    "d['PCT OVERWEIGHT'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputar Valores Perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un data frame en base a números aleatorios.\n",
    "df = pd.DataFrame(np.random.randn(5, 3), index=['a0', 'a10','a20', 'a30', 'a40'],columns=['X', 'Y', 'Z'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear índices adicionales al data frame.\n",
    "df2 = df.reindex(['a0', 'a1', 'a10', 'a11', 'a20', 'a21','a30', 'a31', 'a40', 'a41'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores perdidos con ceros.\n",
    "df3 = df2.fillna(0)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores con valores diferentes por variable mediante un diccionario\n",
    "values = {'X': 10, 'Y': 20, 'Z': 30}\n",
    "df4 = df2.fillna(values)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores perdidos con el método “forward propagation”. Se va completar con el valor previo al nulo.\n",
    "df5 = df2.fillna(method='pad')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores perdidos con el promedio de la variable.\n",
    "df6 = df2.fillna(df2.mean())\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar los valores perdidos con la mediana de determinadas variables.\n",
    "df7 = df2[['X','Y']].fillna(df2[['X','Y']].median())\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra 1: \n",
    "\n",
    "## Trabajando con un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar un archivo csv y leer los 5 primeros casos.\n",
    "df = pd.read_csv('data/students.csv')\n",
    "df['AREA NAME'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['GRADE LEVEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRADE LEVEL'] == 'ELEMENTARY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar casos específicos.\n",
    "df[(df['GRADE LEVEL'] == 'ELEMENTARY') & (df['COUNTY'] == 'YATES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['COUNTY','AREA NAME']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a mayúsculas.\n",
    "df['AREA NAME'][0:5].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convertir a minúsculas.\n",
    "df['AREA NAME'][0:5].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convertir a minúsculas.\n",
    "df['AREA NAME'][0:5].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantificar la cantidad de caracteres de cada elemento.\n",
    "df['AREA NAME'][0:5].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cortar en base a espacios en blanco.\n",
    "df['AREA NAME'][0:5].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cortar en base a espacios en blanco.\n",
    "df['AREA NAME'][0:5].str.split(' ').str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar\n",
    "df['AREA NAME'][0:5].str.replace('DISTRICT$', 'DIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AREA NAME'][0:5].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df['AREA NAME'][0:5].str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra 2:\n",
    "\n",
    "## Concatenación de DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos los 5 primeros registros de 2 campos.\n",
    "d[['AREA NAME', 'COUNTY']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partir los datos en dos grupos. Concatenarlos por posición.\n",
    "p1 = d[['AREA NAME', 'COUNTY']][0:2] \n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = d[['AREA NAME', 'COUNTY']][2:5]\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([p1,p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar datos en base a una llave.\n",
    "concatenated = pd.concat([p1,p2], keys = ['p1','p2'])\n",
    "concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seleccionar la data agregada en base a una llave.\n",
    "concatenated.loc['p1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos un subconjunto de elementos y promediamos.\n",
    "data = df[df['GRADE LEVEL'] == 'ELEMENTARY']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZIP CODE'] = df['ZIP CODE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NO. OBESE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NO. OBESE'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La suma total.\n",
    "data['NO. OBESE'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor máximo.\n",
    "data['NO. OBESE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor mínimo.\n",
    "data['NO. OBESE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desviación Estándar.\n",
    "data['NO. OBESE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo.\n",
    "data = df[(df['GRADE LEVEL'] == 'ELEMENTARY') &(df['COUNTY'] == 'DELAWARE')]\n",
    "data['COUNTY'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['CITY','LOCATION CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datos\n",
    "grade_lookup = {'GRADE LEVEL': pd.Series(['ELEMENTARY','MIDDLE/HIGH', 'MISC']),'LEVEL': pd.Series([1, 2, 3])}\n",
    "grade_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_lookup2 = pd.DataFrame(grade_lookup)\n",
    "grade_lookup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeros 5 elementos del campo GRADE LEVEL\n",
    "df['GRADE LEVEL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Join\n",
    "d_sub = df.join(grade_lookup2.set_index(['GRADE LEVEL']), on=['GRADE LEVEL'], how='inner')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left Join.\n",
    "d_sub = df.join(grade_lookup2.set_index(['GRADE LEVEL']), on=['GRADE LEVEL'], how='left')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Outer Join.\n",
    "d_sub = df.join(grade_lookup2.set_index(['GRADE LEVEL']),on=['GRADE LEVEL'], how='outer')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método merge\n",
    "d_sub = pd.merge(df, grade_lookup2, on=['GRADE LEVEL'], how='outer')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sub = pd.merge(df, grade_lookup2, left_on=['GRADE LEVEL'], right_on=['GRADE LEVEL'], how='inner')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sub = pd.merge(df, grade_lookup2.set_index(['GRADE LEVEL']), left_on=['GRADE LEVEL'], right_index=True, how='inner')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sub = pd.merge(df.set_index(['GRADE LEVEL']), grade_lookup2, left_index=True, right_on=['GRADE LEVEL'], how='inner')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sub = pd.merge(df.set_index(['GRADE LEVEL']), grade_lookup2.set_index(['GRADE LEVEL']), left_index=True, right_index=True, how='inner')\n",
    "d_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra 3:\n",
    "\n",
    "## Agrupaciones en un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group By\n",
    "df.groupby('GRADE LEVEL')['NO. OBESE'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL')['NO. OBESE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL')['NO. OBESE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL')['NO. OBESE'].aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL')['NO. OBESE'].agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL')['NO. OBESE'].agg(suma = sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['COUNTY','GRADE LEVEL'])['NO. OBESE'].agg(suma = sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('GRADE LEVEL').agg(suma_NO_OBESES = ('NO. OBESE', sum),\n",
    "                              count_NO_OBESES = ('NO. OVERWEIGHT', len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['COUNTY','GRADE LEVEL']).agg(suma_NO_OBESES = ('NO. OBESE', sum),\n",
    "                                         count_NO_OBESES = ('NO. OVERWEIGHT', len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
