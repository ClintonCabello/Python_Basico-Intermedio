{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Sesión 13: Regresión Logística con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuga (churn) de clientes con Regresión Logística\n",
    "Una compañía de telecomunicaciones está preocupada por la cantidad de clientes que abandonan su negocio de telefonía fija por competidores de cable. Necesitan entender quién se va. Imagina que eres analista de esta empresa y tienes que averiguar quién se va y por qué."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Vamos a importar las librerías requeridas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2 id=\"about_dataset\">Sobre el archivo de datos</h2>\n",
    "Utilizaremos un conjunto de datos de telecomunicaciones para predecir la pérdida de clientes. Este es un conjunto de datos de clientes históricos donde cada fila representa un cliente. Los datos son relativamente fáciles de entender y puedes descubrir información que puedes usar de inmediato. Por lo general, es menos costoso mantener clientes que adquirir nuevos, por lo que el enfoque de este análisis es predecir los clientes que se quedarán con la empresa.\n",
    "\n",
    "\n",
    "Este conjunto de datos proporciona información para ayudarte a predecir qué comportamiento te ayudará a retener clientes. Puedes analizar todos los datos relevantes del cliente y desarrollar programas enfocados en la retención de clientes.\n",
    "\n",
    "\n",
    "\n",
    "El conjunto de datos incluye información sobre:\n",
    "- Clientes que se fueron en el último mes: la columna se llama Churn.\n",
    "- Servicios a los que se ha suscrito cada cliente: teléfono, líneas múltiples, Internet, seguridad en línea, respaldo en línea, protección del dispositivo, soporte técnico y transmisión de TV y películas.\n",
    "- Información de la cuenta del cliente: cuánto tiempo han sido clientes, contrato, método de pago, facturación electrónica, cargos mensuales y cargos totales.\n",
    "- Información demográfica sobre los clientes: género, rango de edad y si tienen socios y dependientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "###  Carga los datos de Telco Churn\n",
    "Telco Churn es un archivo de datos hipotéticos que se refiere a los esfuerzos de una empresa de telecomunicaciones para reducir la rotación en su base de clientes. Cada caso corresponde a un cliente separado y registra diversa información demográfica y de uso del servicio. Antes de poder trabajar con los datos, debes usar la URL para obtener ChurnData.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Carga la data del archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "churn_df = pd.read_csv(\"data/ChurnData.csv\")\n",
    "churn_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"preprocessing\">Pre-procesamiento y selección de la data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seleccionar algunas características para el modelado. También, cambiar el tipo de datos de destino para que sea entero, ya que es un requisito del algoritmo scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n",
    "churn_df['churn'] = churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir <b>X</b>, and <b>y</b> para nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(churn_df['churn'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, nosotros normalizamos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, dividimos nuestro conjunto de datos en un conjunto de entrenamiento y de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"modeling\">Modelando (Regresión Logística con Scikit-learn)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir nuestro modelo usando __LogisticRegression__ del paquete Scikit-learn. Esta función implementa la regresión logística y puedes usar diferentes optimizadores numéricos para encontrar parámetros, incluidos los solucionadores 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'. Puedes buscar información extensa sobre las ventajas y desventajas de estos optimizadores si los buscas en Internet.\n",
    "<br>La versión de Regresión logística en Scikit-learn, admite la regularización. La regularización es una técnica utilizada para resolver el problema de sobreajuste en los modelos de aprendizaje automático.</br>\n",
    "<br> El parámetro **C** indica el __inverso de la intensidad de regularización__, que debe ser un float positivo. Los valores más pequeños especifican una regularización más fuerte.</br>\n",
    "Ahora ajustemos nuestro modelo con el conjunto de datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos los componentes del modelo de regresión obtenido\n",
    "dir(LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente comando mostramos los coeficientes recultantes del análisis de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip'])\n",
    "LR.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nosotros podemos predecir con nuestro data de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__predict_proba__  devuelve estimaciones para todas las clases, ordenadas por la etiqueta de clases. Entonces, la primera columna es la probabilidad de la clase 1, P(Y=1|X), y la segunda columna es la probabilidad de la clase 0, P(Y=0|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"evaluation\">Evaluación</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índice de jaccard\n",
    "Probemos el índice jaccard para la evaluación de precisión. Podemos definir jaccard como el tamaño de la intersección dividido por el tamaño de la unión de dos conjuntos de etiquetas. Si el conjunto completo de etiquetas pronosticadas para una muestra coincide estrictamente con el conjunto real de etiquetas, la precisión del subconjunto es 1.0; de lo contrario es 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "Otra forma de ver la precisión del clasificador es mirar la __matriz de confusión__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mira la primera fila. La primera fila es para clientes cuyo valor de churn real en el conjunto de prueba es 1.\n",
    "Como puedes calcular, de 40 clientes, el valor de churn de 15 de ellos es 1.\n",
    "Y de estos 15, el clasificador predijo correctamente 6 de ellos como 1 y 9 de ellos como 0.\n",
    "\n",
    "Significa que, para 6 clientes, el valor de churn real era 1 en el conjunto de prueba, y el clasificador también predijo correctamente esos como 1. Sin embargo, mientras que la etiqueta real de 9 clientes era 1, el clasificador predijo aquellos como 0, lo que no es muy bueno. Podemos considerarlo como un error del modelo para la primera fila.\n",
    "\n",
    "¿Qué pasa con los clientes con valor 0 de churn? Veamos la segunda fila.\n",
    "Parece que había 25 clientes cuyo valor de churn era 0.\n",
    "\n",
    "\n",
    "El clasificador pronosticó correctamente 24 de ellos como 0, y uno de ellos erróneamente como 1. Por lo tanto, ha hecho un buen trabajo al predecir a los clientes con un valor 0 de churn. Lo bueno de la matriz de confusión es que muestra la capacidad del modelo para predecir correctamente o separar las clases. En el caso específico del clasificador binario, como este ejemplo, podemos interpretar estos números como el recuento de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En función del recuento de cada sección, podemos calcular la precisión y la recuperación de cada etiqueta:\n",
    "\n",
    "\n",
    "- __Precision__ es una medida de la precisión siempre que se haya predicho una etiqueta de clase. Se define por: precisión = TP / (TP + FP)\n",
    "\n",
    "- __Recall__ Es la verdadera tasa positiva. Se define como: Recall =  TP / (TP + FN)\n",
    "\n",
    "    \n",
    "Entonces, podemos calcular precision y recall para cada clase.\n",
    "\n",
    "__F1 score:__\n",
    "Ahora estamos en condiciones de calcular los puntajes F1 para cada etiqueta en función de la precisión y la recuperación de esa etiqueta.\n",
    "\n",
    "El puntaje F1 es el promedio armónico de la precisión y la recuperación, donde un puntaje F1 alcanza su mejor valor en 1 (precisión perfecta y recuperación) y el peor en 0. Es una buena manera de mostrar que un clasificador tiene un buen valor para ambos precision y recall.\n",
    "\n",
    "\n",
    "Y finalmente, podemos decir que la precisión promedio para este clasificador es el promedio del puntaje F1 para ambas etiquetas, que es 0,72 en nuestro caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy Score: \", metrics.accuracy_score(y_test, yhat))\n",
    "print(\"Confusion Matrix:\\n \", metrics.confusion_matrix(y_test, yhat))\n",
    "print(\"Precision Score: \", metrics.precision_score(y_test, yhat))\n",
    "print(\"Recall Score: \", metrics.recall_score(y_test, yhat))\n",
    "print(\"F1 Score: \", metrics.f1_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss\n",
    "Ahora, intentemos __log loss__ para la evaluación. En la regresión logística, el resultado puede ser la probabilidad de que el abandono del cliente sea sí (o igual a 1). Esta probabilidad es un valor entre 0 y 1.\n",
    "La __log loss__ (pérdida logarítmica) mide el rendimiento de un clasificador donde la salida predicha es un valor de probabilidad entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (curva ROC)\n",
    "\n",
    "Una curva ROC (curva de característica operativa del receptor) es un gráfico que muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. Esta curva representa dos parámetros:\n",
    "\n",
    "* Tasa de verdaderos positivos (TPR)\n",
    "* Tasa de falsos positivos (FPR)\n",
    "\n",
    "Una curva ROC representa TPR frente a FPR en diferentes umbrales de clasificación. Reducir el umbral de clasificación clasifica más elementos como positivos, por lo que aumentarán tanto los falsos positivos como los verdaderos positivos. Como la curva ROC es una función, para interpretarla se emplea el área bajo la curva (AUC). AUC representa la probabilidad de que una muestra positiva se sitúe con un score superior al de una muestra negativa. Podemos llamarlo su poder de discriminación.\n",
    "\n",
    "A modo de guía para interpretar las curvas ROC se han establecido los siguientes intervalos para los valores de AUC:\n",
    "\n",
    "* [0.5]: Es como lanzar una moneda.\n",
    "* [0.5, 0.6): rendimiento malo.\n",
    "* [0.6, 0.75): rendimiento regular.\n",
    "* [0.75, 0.9): rendimiento bueno.\n",
    "* [0.9, 0.97): rendimiento muy bueno.\n",
    "* [0.97, 1): rendimiento excelente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, threshold = roc_curve(y_test, yhat)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutando con varios optimizadores y reguladores\n",
    "Construiremos el modelo de Regresión logística nuevamente para el mismo conjunto de datos, pero esta vez, usa diferentes valores de <b>solver</b> y <b>regularization</b>. Con esto podemos hacer comparaciones de varios modelos hasta encontrar el más adecuado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "Cs=[0.01,0.02,0.05,0.1]\n",
    "\n",
    "for s in solvers:\n",
    "    for c in Cs:\n",
    "        LR = LogisticRegression(C=c, solver=s).fit(X_train,y_train)\n",
    "        yhat = LR.predict(X_test)\n",
    "        yhat_prob = LR.predict_proba(X_test)\n",
    "        log_loss(y_test, yhat_prob)\n",
    "        fpr, tpr, threshold = roc_curve(y_test, yhat)\n",
    "        print(\"Solver=\"+s+\", C=\"+str(c)+\n",
    "              \"->Accuracy: \"+str(metrics.accuracy_score(y_test, yhat)) + \n",
    "             \"->Log Loss : \"+str(log_loss(y_test, yhat_prob)) +\n",
    "             \"->AUC : \"+str(auc(fpr, tpr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
